\documentclass[11pt]{article}

\usepackage{amsmath,amsfonts,amssymb,amsthm,verbatim,multirow,hyperref,subfig,footnote,graphicx,array,xr,booktabs}
\usepackage{times}
\usepackage[textheight=600pt]{geometry}
\usepackage[usenames,dvipsnames]{color}
%%%%%%%%%%%%%%
%\usepackage[spanish]{babel}
%\usepackage[utf8]{inputenc}
%%%%%%%%%%%%%



% \oddsidemargin 0pt
% \topmargin 0pt
% \headheight 0pt
% \headsep 0pt
% \textwidth 15cm  
% \textheight  24cm
% \footskip 1cm

\newcommand{\lb}[1]{\color{ForestGreen}\textbf{[Luis B.: #1]}\normalcolor}
\newcommand{\bl}[1]{\color{red}\textbf{[Bo: #1]}\normalcolor}
\newcommand{\jeg}[1]{\color{blue}\textbf{Julien: #1]}\normalcolor}

\begin{document}
\begin{center}
  {\Large \textbf{Response to the comments of the Referee \#2.}}
\end{center}

We are grateful for the reviewer's careful commentary on the paper, which has improved
our presentation of the article. In what follows, we state the reviewer's
comments in italics, and describe our response in roman.

\begin{itemize}
\item \textit{The above is particularly important when it comes to the proxy
  dimension reduction; in a properly specified hierarchical model,
  such as in the paper, the main loss from reducing the proxies is an
  increased prediction uncertainty for the temperature and model
  parameters.  For a "reverse" specified model, I would expect
  hard-to-avoid bias and incorrect conclusions about appropriate
  number of proxies etc, if those are treated as covariates to be
  "selected". Having them as model responses removes that part of the
  tendency to treat it as a model selection problem, when the
  dimension reduction is really done for basic computational cost
  reasons; The model should (ideally) be defined so that the original
  proxies could be used, given enough computational power.  It should
  be made clearer if the computational cost reduction is the only
  reason for doing this, or if it also might reduce individual proxy
  biases by averaging some of them out.  Reducing the proxies by
  averaging (or otherwise) within groups removes information relevant
  for uncertainty quantification, so it should be made clear what such
  information might be lost in the dimension reduction step. The above also relates to the discussion on page 10; using the
  proxies as "input"/"covariates" would definitely run the risk of
  ignoring them. The generative hierarchical construction used in the
  paper makes them much less ignorable, as they are the means through
  which everything else is estimated.}

We really thank the reviewer for these important comments. We are aware that
modeling proxies individually would reduce local estimation bias. The variance
at a local perspective would increase considerably, and this is one reason why
we prefer to concentrate on modeling the average temperature only. It is a fact
that if we had considered the individual proxies, the computational difficulties
would have increased, especially in the MCMC case. The reconstruction taking
individual proxies at a spatio-temporal level with INLA will definitely be a
future project, but we cannot get rid of the above problem even in this case.
That is why we consider that the dimension reduction techniques should be
utilized in any way.
\bl{Let's wait to see the results from the new model}

\item \textit{Are the reduced proxy model residuals temporally independent? (see
  comment above) May need to add an AR(1) random effect to the model to capture
  dependence (but be careful about confounding with the independent
  noise term that forms the response likelihood; ideally, one would
  have a joint BYM model that parametrises the joint effect).}

We analyzed the behavior of the residuals based on the linear regression of
each of the 8 reduced proxies vs the observed temperatures and we got enough
evidence to reject the hypothesis of temporal independence in 5 out of 40
possible residuals (5 reduced-proxy methods $\times$ 8 reduced proxies). Based
on the above we think that the temporal independence assumption is fair enough.
Despite the above, we implemented an AR(1) random effect to the model as you
suggested. The results are shown in Table \ref{tab:comparisontot}. In general
all the measures are slightly smaller using the AR(1) error term, but the best
models chosen in the article are still the same. We think that the difference in
terms of validation measures is not considerable to change our simpler
assumption of an i.i.d error term.   

\bl{Yes, we assumed independent residuals. Barboza et al. (2014) found that the
  error structure is unimportant when forcings are included in the
  reconstruction, but now we also had reconstruction without forcings, so I am
  not sure how to address this question. Should we try the AR(1) model as
  well?}\lb{I'm trying a model with AR(1) errors to see if there is an
  evident change}

\begin{table}
  \centering
  {\small
\begin{tabular}{lll|rrr|r}
  \toprule
\textbf{Model} & N & \textbf{Method} & $IS_{80}$ & $IS_{95}$ & CRPS & MSE \\ 
  \midrule
WF & 1 & PCR & 0.4595 & 0.1759 & 0.1536 & 0.1475 \\ 
WF & 1 & sPCR & 0.5105 & 0.1952 & 0.1850 & 0.1885 \\ 
WF & 1 & LASSO & 0.4572 & 0.1749 & 0.1569 & 0.1738 \\ 
WF & 1 & SPLS & 0.4978 & 0.1904 & 0.1873 & 0.1689 \\ 
  WF & 1 & SIR & 0.4650 & 0.1779 & 0.1566 & 0.1689 \\
  \midrule
WF & 8 & PCR & 0.2300 & 0.0794 & 0.0893 & 0.0457 \\ 
WF & 8 & sPCR & 0.1848 & 0.0673 & 0.0743 & 0.1028 \\ 
WF & 8 & LASSO & 0.5826 & 0.4019 & 0.1732 & 0.1923 \\ 
WF & 8 & SPLS & 0.3096 & 0.1369 & 0.1092 & 0.1484 \\ 
  WF & 8 & SIR & 0.6647 & 0.4988 & 0.1904 & 0.2156 \\
  \midrule
NF & 8 & PCR & 0.3705 & 0.1157 & 0.1698 & 0.0249 \\ 
NF & 8 & sPCR & 0.3641 & 0.1368 & 0.1350 & 0.0250 \\ 
NF & 8 & LASSO & 0.6083 & 0.4329 & 0.1788 & 0.1983 \\ 
NF & 8 & SPLS & 0.2844 & 0.1129 & 0.1025 & 0.1398 \\ 
  NF & 8 & SIR & 0.3753 & 0.1856 & 0.1265 & 0.1477 \\
  \midrule
Mixed & 8 & PCR & 0.4774 & 0.1439 & 0.2255 & 0.0444 \\ 
Mixed & 8 & sPCR & 0.3366 & 0.1260 & 0.1226 & 0.0284 \\ 
Mixed & 8 & LASSO & 0.5988 & 0.4214 & 0.1769 & 0.1959 \\ 
Mixed & 8 & SPLS & 0.2830 & 0.1118 & 0.1022 & 0.1395 \\ 
Mixed & 8 & SIR & 0.3735 & 0.1837 & 0.1261 & 0.1468 \\ 
   \bottomrule
\end{tabular}
}
\caption{Comparison of predictive measures with an AR(1) error term.}
\label{tab:comparisontot}
\end{table}


\item \textit{What is the prior used for the weights on the B-spline basis
  constructions? For independent weights, the results can be highly
  dependent on the location and spacing of the knots. A nearly always
  better alternative is to use a properly penalised spline with a well
  defined interpretation in the limit as the number of knots approach
  infinity, such as a continuous domain 2nd order random walk model
  (when penalisisng the integral of the square of the 2nd order
  derivatives, which gives a 2nd order intrinsic stationary prior on
  the weights; in INLA either a "rw2" model can be used for the
  continuous limit, or a 1D SPDE model on 2nd order B-spline bases).}

We are also aware that possibly there exists a high dependence of the results on the location and spacing of the knots as the
reviewer emphasizes, this is why we fixed the knots location based on the
degree of linear association between the true temperatures and the BSplines. In
addition, we know
that the knots spacing is a difficult problem to work with, mainly because of the
nature of the temperature series and its diverse spatial composition, this is
why we think that the assumption of a continuous time model is a complex and
ambitious assumption. We prefer our simpler and more conservative assumption of uniformity in the distribution of nodes.    
\bl{It sounds complicated, but the reviewer pointed the function in INLA to use,
  so we may try the ``rw2" model?}\lb{Yes, it is quite complicated mostly
  because the penalization term that the reviewer is suggesting. I prefer to defend our position here.}

\item \textit{Page 12: The method is referred to as "Sampling with INLA", but it's
  not clear if only the direct posterior density computations were
  used, or if also the independent Monte Carlo posterior sample method
  available in R-INLA was also used (even apart from the sampling
  error inherent in estimates based on Monte Carlo samples, this
  sampling method does not exactly match the computed marginal
  posteriors).  Since the model is linear, all the results should be
  accessible through the direct methods, but then it would be sensible
  to refer to the method differently, e.g. "Computing posteriors with
  INLA". If posterior samples are used, it should be made clear in the
  text.} 

Thanks for the clarification. We used the direct posterior density computations
for most of the calculations throughout the article, except when we compute the
CRPS measure where we used Monte Carlo samples to construct the independent
samples within its definition. We clarified this in the article. \lb{I have to do this...}  

\item \textit{"Model (4) leads to conditional independence of $y$ given $\theta$ and
  $\psi$": Conditional independence between the response variables (the
  reduced proxy values) is a simplifying restriction of the R-INLA
  implementation, separate from the the prior independence between
  different structured random effects components. While conditional
  independence between proxies seems reasonable (note \textbf{conditional}
  independence, as one should expect strong \textbf{marginal} dependence, as
  noted also on page 9), I have a harder time accepting conditional
  independence within each proxy; are the model residuals really
  statistically independent over time?}

Please see the answer above.

\item \textit{What $f(.)$ models were used for the different inputs? (see comment
  about rw2 etc, above) Linear? rw2? Other?}

We used an i.i.d. random effect for the latent variable $T_t$ and we made as
many copies as necessary of $T_t$ in order to define the latent variable
multiplied by a random variable in each proxy equation. In addition, we added an
independent random effect to model the error term in the latent equation and
afterwards this
last term was changed to an AR(1) random effect following your suggestion.  

\item \textit{Page 13: "(ii) the vector $\theta$ is conditionally independent given
  the hyperparameters"; this statement is unclear. The R-INLA model
  components are conditionally independent, but any structured effect
  will have conditional dependence within such a components, so it's
  not correct to say that the entire $\theta$ vector is conditionally
  independent (unless it's meant to refer only to a specific subset of
  models, but the preceeding text seems to descrive the general INLA
  model setting). The next sentence, "These two assumptions specify $\theta$ as a
  Gaussian Markov random field" is also not quite right; \textbf{all}
  multivariate normal distributions are markov random fields on \textbf{some}
  graph. The key is that for models such as "iid" and "AR(1)", "rw2",
  etc, that graph is very very sparse, so that the Markov property on
  that graph becomes useful for computations.} 

Thanks for this important clarification. We deleted both sentences to make the complete
paragraph correct. 


\item \textit{Page 13, last line: delete "their" in "their approximations"; there
  might be other approximations!}
  
Thanks, we changed the sentence as you suggested.

\item \textit{It's not clear what the differences between the models estimated
  with MCMC and INLA are in Figure 8. The text implies that the model
  estimated with MCMC uses the same priors (and model structure) as in
  Barboza et al (2014). Is the systematic difference in reconstruction
  mean only due to the difference in priors for the model component
  variances?  If the two models are the same, some more effort should
  be put on determining why the posterior means are so different. If
  the two models are different (which includes all the parameter prior
  distributions), could another INLA run be done where exactly the
  same priors as for the MCMC run is used, so that it's possible to
  see if the two methods compute/estimate the same posteriors?}

\bl{I think we used the same model. The two plots have the same calibration period?}

\item \textit{The computational cost benefit of INLA seems very clear; there is
  only a small number of variance parameters in the model, and the
  lack of explicit temporal dependence (other than that implied by the
  forcings) means that MCMC is overkill for this problem, and inposes
  a large Monte Carlo error; Even with explicit random temporal
  dependence in the model, the likelihood calculations would be order
  N in cost, and would only add one extra covariance parameter, so
  INLA should be expected to be more efficient.  Also, since the
  entire model is Gaussian, the Laplace steps are exact, so only the
  mode seeking and numerical integration steps are approximations.
  Thus, the absolute Monte Carlo error from MCMC should be expected to
  be large unless a very long run is made, and the relative bias in
  the posterior densities from INLA should be expected to be small.}

\bl{The first part seems to suggest to run an model with AR(1) errors, and the second part still seems to suggest further investigation between INLA and full MCMC? }

\item \textit{I'm curious about the bimodal posterior density for the Greenhouse
  effect in Figure 9, as I wouldn't expect that from a model of this
  simple type.  How was the figure produced? If done via posterior
  sampling, how many samples? The number of samples needs to be very
  large to get stable empirical density estimates.}
\jeg{I have the same question, actually}
...

\item \textit{I really like that several assessment criteria are used; it's clear
  from the table that relying on only one would run the risk of
  overinterpreting the method differences.}

...

\end{itemize}
\end{document}


